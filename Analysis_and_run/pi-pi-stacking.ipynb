{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as mda\n",
    "import MDAnalysis.transformations as trans\n",
    "import numpy as np\n",
    "side_atom = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \n",
    "             \"C21\", \"C22\", \"C23\", \"C24\", \"C25\", \"C26\", \"C27\", \"C28\"]\n",
    "\n",
    "# upwrap structures and select backbone molecules\n",
    "side_atom_selection = \" or \".join([f\"name {atom}\" for atom in side_atom])\n",
    "u = mda.Universe(f'../bulk/bulk.tpr', f'../bulk/bulk_pbc.gro')\n",
    "u.trajectory.add_transformations(trans.unwrap(u.atoms))\n",
    "molecule = u.select_atoms(f'name C* O* S* and not (resname PT* and ({side_atom_selection})) and not (resname PT* and name O*) and not (resname P2O and name O1 O2)')\n",
    "\n",
    "molecule.write(\"../bulk/backbone.gro\")\n",
    "print(f\"Selected {len(molecule)} atoms.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2O\n",
    "DBZ = u.select_atoms('(resname PT* and name C35 C36 C37 C38 C39 C40 C41 C42 C43 C44 C45 C46 S5)')\n",
    "DBZ_2O = u.select_atoms('resname P2O and name C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C25 C26')\n",
    "PTO = u.select_atoms(f'resname PT* and name C13 C14 C15 C16 C17 C18 C31 C32 C33 C34 S4 S2')\n",
    "BEZ1 = u.select_atoms(f'resname P2O and name C11 C12 C13 C14 C23 C24') #接DBZ\n",
    "BEZ2 = u.select_atoms(f'resname P2O and name C17 C18 C19 C20 C21 C22')\n",
    "\n",
    "## PSO2\n",
    "DBZ = u.select_atoms('(resname PT* and name C35 C36 C37 C38 C39 C40 C41 C42 C43 C44 C45 C46 S5)')\n",
    "DBZ_2O = u.select_atoms('resname SO2 and name C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 S3')\n",
    "PTO = u.select_atoms(f'resname PT* and name C13 C14 C15 C16 C17 C18 C31 C32 C33 C34 S4 S2')\n",
    "BEZ1 = u.select_atoms(f'resname SO2 and name C3 C4 C5 C6 C19 C20') #接DBZ\n",
    "BEZ2 = u.select_atoms(f'resname SO2 and name C21 C22 C23 C24 C25 C26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"PSO2-pipi\" # output file name\n",
    "\n",
    "# read structure file\n",
    "u = mda.Universe(f'../bulk/backbone.gro')\n",
    "DBZ = u.select_atoms('(resname PT* and name C35 C36 C37 C38 C39 C40 C41 C42 C43 C44 C45 C46 S5)')\n",
    "DBZ_2O = u.select_atoms('resname SO2 and name C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 S3')\n",
    "PTO = u.select_atoms(f'resname PT* and name C13 C14 C15 C16 C17 C18 C31 C32 C33 C34 S4 S2')\n",
    "BEZ1 = u.select_atoms(f'resname SO2 and name C3 C4 C5 C6 C19 C20')\n",
    "BEZ2 = u.select_atoms(f'resname SO2 and name C21 C22 C23 C24 C25 C26')\n",
    "\n",
    "#cutoff range to see how parallel are normals to the plane of each monomer\n",
    "parallelrange = 0.10\n",
    "#cutoff radius for finding possbible CENTROID neighbors\n",
    "cutoff = 15 ##Anstom\n",
    "#cutoff distance for pistacks CENTROID in vertical (normal to their plane) and horizental (parallel to\n",
    "verticalcutoff = 5 ##Anstom\n",
    "horizentalcutoff = 5\n",
    "#index.ndx is the index file for atoms exist in conjugated structure \n",
    "#that one wants to consider/total atoms in index file should be devisible by \"number\"\n",
    "half_box= u.dimensions[1]/2 #Anstom\n",
    "\n",
    "#calculate center of mass of each fragment\n",
    "def COM(mol):\n",
    "    com = mol.center_of_mass(compound='residues')\n",
    "    return com\n",
    "\n",
    "DBZ_com = COM(DBZ)\n",
    "DBZ_2O_com = COM(DBZ_2O)\n",
    "PTO_com = COM(PTO)\n",
    "BEZ1_com = COM(BEZ1)\n",
    "BEZ2_com = COM(BEZ2)\n",
    "\n",
    "# calculate fragment normal vector\n",
    "def com_vec(mol, com):\n",
    "    a1= mol.atoms[0].position\n",
    "    a2= mol.atoms[1].position\n",
    "\n",
    "    v1 = a1-com\n",
    "    v2 = a2-com\n",
    "    normal_vector = np.cross(v1, v2)/np.linalg.norm(np.cross(v1,v2))\n",
    "    return normal_vector\n",
    "\n",
    "DBZ_vec = com_vec(DBZ, DBZ_com)\n",
    "DBZ_2O_vec = com_vec(DBZ_2O, DBZ_2O_com)\n",
    "PTO_vec = com_vec(PTO, PTO_com)\n",
    "BEZ1_vec = com_vec(BEZ1, BEZ1_com)\n",
    "BEZ2_vec = com_vec(BEZ2, BEZ2_com)\n",
    "\n",
    "# Save information for each fragment into COM_DICT. This includes the center of mass (COM) and normal vectors.\n",
    "COM_DICT = [\n",
    "    list(zip(DBZ_com, DBZ_vec)),  \n",
    "    list(zip(DBZ_2O_com, DBZ_2O_vec)), \n",
    "    list(zip(PTO_com, PTO_vec)), \n",
    "    list(zip(BEZ1_com, BEZ1_vec)),\n",
    "    list(zip(BEZ2_com, BEZ2_vec))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for parallel fragments in COM_DICT based on their normal vectors.\n",
    "def check_parallel(COM_DICT, parallelrange):\n",
    "    PARALLEL = []\n",
    "    for frag_idx1, fragment1 in enumerate(COM_DICT):\n",
    "        # Check parallelism within the same fragment\n",
    "        for i in range(len(fragment1)):\n",
    "            for j in range(i + 1, len(fragment1)):\n",
    "                com1, normal1 = fragment1[i]\n",
    "                com2, normal2 = fragment1[j]\n",
    "                cos_similarity = np.dot(normal1, normal2) / (np.linalg.norm(normal1) * np.linalg.norm(normal2))\n",
    "                if (1.0 - parallelrange) < cos_similarity < (1.0 + parallelrange):\n",
    "                    PARALLEL.append((frag_idx1, i, frag_idx1, j))\n",
    "        # Check parallelism between different fragments\n",
    "        for frag_idx2, fragment2 in enumerate(COM_DICT):\n",
    "            if frag_idx1 >= frag_idx2:\n",
    "                continue\n",
    "            for i in range(len(fragment1)):\n",
    "                for j in range(len(fragment2)):\n",
    "                    com1, normal1 = fragment1[i]\n",
    "                    com2, normal2 = fragment2[j]\n",
    "                    cos_similarity = np.dot(normal1, normal2) / (np.linalg.norm(normal1) * np.linalg.norm(normal2))\n",
    "                    if (1.0 - parallelrange) < cos_similarity < (1.0 + parallelrange):\n",
    "                        PARALLEL.append((frag_idx1, i, frag_idx2, j))\n",
    "\n",
    "    return PARALLEL\n",
    "# Find parallel fragment pairs. The output is a list of tuples in the format:\n",
    "# [(residue1_index, fragment1_index, residue2_index, fragment2_index)]\n",
    "parrel_pairs = check_parallel(COM_DICT, parallelrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pi-pi stacking pairs are within the cutoff distance\n",
    "def NEIGHBOR(parrel_pairs, COM_DICT):\n",
    "    neighbor = []\n",
    "    for pair in parrel_pairs:\n",
    "        residue_1 = pair[0] \n",
    "        residue_2 = pair[2] \n",
    "        frag_1 = pair[1]\n",
    "        frag_2 = pair[3]\n",
    "        com1 = COM_DICT[residue_1][frag_1][0] \n",
    "        com2 = COM_DICT[residue_2][frag_2][0]\n",
    "        dist_vector = com2 - com1\n",
    "        dist_vector -= np.round(dist_vector / (2 * half_box)) * (2 * half_box) \n",
    "        distance = np.linalg.norm(dist_vector)\n",
    "\n",
    "        if distance < cutoff:\n",
    "            neighbor.append(pair)  \n",
    "    return neighbor\n",
    "\n",
    "neighbor_pairs = NEIGHBOR(parrel_pairs, COM_DICT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check horizontal and vertical distances of pairs\n",
    "def HOR_VIR (neighbor_pairs, COM_DICT):\n",
    "    hor_vir = []\n",
    "    hor_dis = []\n",
    "    ver_dis = []\n",
    "    for pair in neighbor_pairs:\n",
    "        residue1 = pair[0]\n",
    "        residue2 = pair[2]\n",
    "        frag_1 = pair[1]\n",
    "        frag_2 = pair[3]\n",
    "        com1, vec1 = COM_DICT[residue1][frag_1][0], COM_DICT[residue1][frag_1][1]\n",
    "        com2, vec2 = COM_DICT[residue2][frag_2][0], COM_DICT[residue2][frag_2][1]\n",
    "        vector1 = np.subtract(com1, com2)\n",
    "        vector1 -= np.round(vector1/(2*half_box))*(2*half_box)\n",
    "        vector2 = vec2\n",
    "        unit_vector1 = vector1/np.linalg.norm(vector1)\n",
    "        unit_vector2 = vector2/np.linalg.norm(vector2)\n",
    "        dot_product = np.dot(unit_vector1, unit_vector2)\n",
    "        sine = np.sqrt(1-dot_product**2)\n",
    "        d_vertical = abs(dot_product)*np.linalg.norm(vector1)\n",
    "        d_horizon = sine*np.linalg.norm(vector1)\n",
    "\n",
    "        if d_vertical < verticalcutoff and d_horizon < horizentalcutoff:\n",
    "            hor_vir.append(pair)\n",
    "            ver_dis.append(d_vertical)\n",
    "            hor_dis.append(d_horizon)\n",
    "    return hor_vir, ver_dis, hor_dis\n",
    "\n",
    "hor_vir_pairs, vertical_dis, horizental_dis = HOR_VIR(neighbor_pairs, COM_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = []\n",
    "BB = []\n",
    "CC = []\n",
    "AB = []\n",
    "AC = []\n",
    "BC = []\n",
    "\n",
    "for pair in hor_vir_pairs:\n",
    "    if (pair[0] == 0 or pair[0] == 1) and (pair[2] == 0 or pair[2] == 1):\n",
    "        AA.append(pair)\n",
    "    elif pair[0] == 2 and pair[2] == 2:\n",
    "        BB.append(pair)\n",
    "    elif (pair[0] == 3 or pair[0] == 4) and (pair[2] == 3 or pair[2] == 4):\n",
    "        CC.append(pair)\n",
    "    elif (pair[0] == 0 or pair[0] == 1) and pair[2] == 2:\n",
    "        AB.append(pair)\n",
    "    elif (pair[0] == 0 or pair[0] == 1) and (pair[2] == 3 or pair[2] == 4):\n",
    "        AC.append(pair)\n",
    "    elif pair[0] == 2 and (pair[2] == 3 or pair[2] == 4):\n",
    "        BC.append(pair)\n",
    "\n",
    "with open(f\"../bulk/{output_file}.txt\" , 'w') as file:\n",
    "    file.write(f\"{len(hor_vir_pairs)}\\n\")\n",
    "    file.write(f\"AA: {len(AA)}\\n\")\n",
    "    file.write(f\"BB: {len(BB)}\\n\")\n",
    "    file.write(f\"CC: {len(CC)}\\n\")\n",
    "    file.write(f\"AB: {len(AB)}\\n\")\n",
    "    file.write(f\"AC: {len(AC)}\\n\")\n",
    "    file.write(f\"BC: {len(BC)}\\n\\n\")\n",
    "    file.write(f\"Ver : {vertical_dis}\\n\")\n",
    "    file.write(f\"Hor : {horizental_dis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = {0: DBZ, 1: DBZ_2O, 2: PTO, 3: BEZ1, 4: BEZ2}\n",
    "\n",
    "selected_atoms = u.select_atoms('') \n",
    "\n",
    "for pair in hor_vir_pairs:\n",
    "    residue1 = pair[0]\n",
    "    residue2 = pair[2]\n",
    "    frag_1 = pair[1]\n",
    "    frag_2 = pair[3]\n",
    "    residue_atoms_1 = name[residue1] & name[residue1].residues[frag_1].atoms\n",
    "    residue_atoms_2 = name[residue2] & name[residue2].residues[frag_2].atoms\n",
    "    selected_atoms += residue_atoms_1 + residue_atoms_2\n",
    "    \n",
    "selected_atoms.write(f\"../bulk/{output_file}.gro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete structure from the GRO file and TPR file\n",
    "u = mda.Universe(f'../bulk/bulk.tpr', f'../bulk/bulk_pbc.gro')\n",
    "DBZ = u.select_atoms('(resname PT* and name C35 C36 C37 C38 C39 C40 C41 C42 C43 C44 C45 C46 S5)')\n",
    "DBZ_2O = u.select_atoms('resname SO2 and name C7 C8 C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 S3')\n",
    "PTO = u.select_atoms(f'resname PT* and name C13 C14 C15 C16 C17 C18 C31 C32 C33 C34 S4 S2')\n",
    "BEZ1 = u.select_atoms(f'resname SO2 and name C3 C4 C5 C6 C19 C20')\n",
    "BEZ2 = u.select_atoms(f'resname SO2 and name C21 C22 C23 C24 C25 C26')\n",
    "name = {0: DBZ, 1: DBZ_2O, 2: PTO, 3: BEZ1, 4: BEZ2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"AA\", \"BB\", \"CC\", \"AB\", \"AC\", \"BC\"]\n",
    "category_counts = {cat: {\"same\": 0, \"not same\": 0} for cat in categories}\n",
    "selected_atoms = u.select_atoms('') \n",
    "# classify pi-pi stacking pairs\n",
    "for pair in hor_vir_pairs:\n",
    "    residue1 = pair[0]\n",
    "    residue2 = pair[2]\n",
    "    frag_1 = pair[1]\n",
    "    frag_2 = pair[3]\n",
    "    atoms1 = name[residue1].residues[frag_1].atoms[0]\n",
    "    atoms2 = name[residue2].residues[frag_2].atoms[0]\n",
    "    fragment1 = atoms1.fragment\n",
    "    fragment2 = atoms2.fragment\n",
    "    # decide pi-pi stacking type\n",
    "    if (residue1 in [0, 1] and residue2 in [0, 1]):\n",
    "        category = \"AA\"\n",
    "    elif residue1 == 2 and residue2 == 2:\n",
    "        category = \"BB\"\n",
    "    elif (residue1 in [3, 4] and residue2 in [3, 4]):\n",
    "        category = \"CC\"\n",
    "    elif (residue1 in [0, 1] and residue2 == 2):\n",
    "        category = \"AB\"\n",
    "    elif (residue1 in [0, 1] and residue2 in [3, 4]):\n",
    "        category = \"AC\"\n",
    "    elif (residue1 == 2 and residue2 in [3, 4]):\n",
    "        category = \"BC\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Determine whether pi-pi stacking pairs are intrachain or interchain\n",
    "    if fragment1 == fragment2:\n",
    "        category_counts[category][\"same\"] += 1\n",
    "    else:\n",
    "        category_counts[category][\"not same\"] += 1\n",
    "\n",
    "for cat in categories:\n",
    "    print(f\"{cat}: [{category_counts[cat]['same']:>3},{category_counts[cat]['not same']:>3}]\")\n",
    "\n",
    "with open(f\"../bulk/{output_file}.txt\" , 'a') as file:\n",
    "    for cat in categories:\n",
    "        file.write(f\"{cat}: [{category_counts[cat]['same']:>3},{category_counts[cat]['not same']:>3}]\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
